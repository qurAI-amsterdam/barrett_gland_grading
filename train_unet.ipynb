{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e43aeff-bbad-45d2-bda3-05e0d004726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wholeslidedata.iterators import create_batch_iterator\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import init_plot, plot_batch, show_plot, print_dataset_statistics\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from nn_archs import UNet\n",
    "from pprint import pprint\n",
    "from torchsummary import summary\n",
    "from wholeslidedata.annotation import utils as annotation_utils\n",
    "from label_utils import to_dysplastic_vs_non_dysplastic\n",
    "from train_unet import load_config\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10125c17-e713-4a41-8249-ca1cfc29e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some colors\n",
    "colors_1 = [\"white\", \"blue\", \"green\", \"orange\", \"red\", 'brown', 'yellow', 'purple', 'pink', 'grey']\n",
    "colors_2 = [\"white\", \"green\", \"red\", \"orange\", 'brown', 'yellow', 'purple', 'pink', 'grey', 'green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3695d4a-d88c-4ff6-be15-683c135e1993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load network config and store in experiment dir\n",
    "user_config = './configs/unet_training_config.yml'\n",
    "train_config = load_config(user_config)\n",
    "\n",
    "# create train and validation generators\n",
    "training_batch_generator = create_batch_iterator(user_config=user_config,\n",
    "                                                 mode='training',\n",
    "                                                 cpus=train_config['cpus'],\n",
    "                                                 number_of_batches=train_config['train_batches'])\n",
    "\n",
    "validation_batch_generator = create_batch_iterator(mode='validation',\n",
    "                                                   user_config=user_config,\n",
    "                                                   cpus=train_config['cpus'],\n",
    "                                                   number_of_batches=train_config['val_batches'])\n",
    "\n",
    "print('\\nTraining dataset ')\n",
    "print_dataset_statistics(training_batch_generator.dataset)\n",
    "print('\\nValidation dataset ')\n",
    "print_dataset_statistics(validation_batch_generator.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c4709-aee5-4060-a1be-32c81236b246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img, cropx, cropy):\n",
    "    _, x, y, _ = img.shape\n",
    "    startx = x // 2 - (cropx // 2)\n",
    "    starty = y // 2 - (cropy // 2)\n",
    "    return img[:, starty:starty + cropy, startx:startx + cropx, :]\n",
    "\n",
    "def plot_center_batch(x, y, y_hat, patches=4):   \n",
    "    \n",
    "    # how many patches to plot\n",
    "    patches = len(y_hat) if patches > len(y_hat) else patches\n",
    "    \n",
    "    # get the prediction\n",
    "    y_hat = torch.argmax(y_hat, dim=1).cpu().detach().numpy()\n",
    "    \n",
    "    # center crop the image\n",
    "    _, h, w = y_hat.shape\n",
    "    x = crop_center(x, h, w)\n",
    "    \n",
    "    print(\"Ground truth\")\n",
    "    fig, axes = init_plot(1, patches, size=(30, 10))\n",
    "    plot_batch(axes, 0, x[:patches], y[:patches], alpha=0.3, colors=colors_2)\n",
    "    plt.show()\n",
    "\n",
    "    # pad and show prediction\n",
    "    print(\"Prediction\")\n",
    "    fig, axes = init_plot(1, patches, size=(30, 10))\n",
    "    plot_batch(axes, 0, x[:patches], y_hat[:patches], alpha=0.3, colors=colors_2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6175a1e-33be-4e1a-9bdb-8a51171206ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally defined UNet (with valid convolutions)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(n_channels=train_config['n_channels'], n_classes=train_config['n_classes'])\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e6f95d-4dc0-45d0-bb2f-36e8cfc2328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_config['learning_rate'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "min_val = float('inf')\n",
    "\n",
    "for n in range(train_config['epochs']):\n",
    "\n",
    "    tr_losses = []\n",
    "    val_losses = []\n",
    "    tr_f1 = []\n",
    "    val_f1 = []\n",
    "\n",
    "    for idx, (x, y, info) in enumerate(tqdm(training_batch_generator, desc='Epoch {}'.format(n+1))):\n",
    "        \n",
    "        # dysplastic vs non-dysplastic\n",
    "        y = to_dysplastic_vs_non_dysplastic(y)\n",
    "        \n",
    "        # store one example as numpy\n",
    "        example_train_batch_x = x\n",
    "        example_train_batch_y = y\n",
    "\n",
    "        # transform x and y\n",
    "        x = torch.tensor(x.astype('float32'))\n",
    "        x = torch.transpose(x, 1, 3).to(device)\n",
    "        y = torch.tensor(y.astype('int64')).to(device)\n",
    "\n",
    "        # forward and update\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model.forward(x)\n",
    "        example_train_batch_y_hat = y_hat\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_losses.append(loss.item())\n",
    "        \n",
    "        # compute f1\n",
    "        y = y.cpu().detach().numpy().flatten()\n",
    "        y_hat = torch.argmax(y_hat, dim=1).cpu().detach().numpy().flatten()\n",
    "        tr_f1.append(f1_score(y, y_hat, average=None))\n",
    "        \n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, y, info) in enumerate(validation_batch_generator):\n",
    "            \n",
    "            # dysplastic vs non-dysplastic\n",
    "            y = to_dysplastic_vs_non_dysplastic(y)         \n",
    "            \n",
    "            # store one example as numpy\n",
    "            example_val_batch_x = x\n",
    "            example_val_batch_y = y\n",
    "\n",
    "            # transform x and y\n",
    "            x = torch.tensor(x.astype('float32'))\n",
    "            x = torch.transpose(x, 1, 3).to(device)\n",
    "            y = torch.tensor(y.astype('int64')).to(device)\n",
    "\n",
    "            # forward and validate\n",
    "            y_hat = model.forward(x)\n",
    "            example_val_batch_y_hat = y_hat\n",
    "            loss = criterion(y_hat, y)\n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "            # compute f1\n",
    "            y = y.cpu().detach().numpy().flatten()\n",
    "            y_hat = torch.argmax(y_hat, dim=1).cpu().detach().numpy().flatten()\n",
    "            val_f1.append(f1_score(y, y_hat, average=None))\n",
    "\n",
    "    # compute & plot metrics\n",
    "    avg_tr_loss = np.mean(tr_losses)\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    avg_tr_f1 = np.round(np.mean(np.asarray(tr_f1), axis=0), decimals=2)\n",
    "    avg_val_f1 = np.round(np.mean(np.asarray(val_f1), axis=0), decimals=2)\n",
    "    print(\"Train loss: {:.3f}, val loss: {:.3f}\".format(avg_tr_loss, avg_val_loss))\n",
    "    print(\"Train dice: {}, val dice: {}\".format(avg_tr_f1, avg_val_f1))\n",
    "    \n",
    "    # plot every 50 epochs\n",
    "    if n % 50 == 0:\n",
    "        print('Training examples: ')\n",
    "        plot_center_batch(example_train_batch_x, example_train_batch_y, example_train_batch_y_hat)\n",
    "        print('Validation examples: ')\n",
    "        plot_center_batch(example_val_batch_x, example_val_batch_y, example_val_batch_y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}