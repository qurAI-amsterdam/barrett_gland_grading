{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e43aeff-bbad-45d2-bda3-05e0d004726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wholeslidedata.iterators import create_batch_iterator\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import init_plot, plot_batch, show_plot, print_dataset_statistics, mean_metrics\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from nn_archs import UNet\n",
    "from pprint import pprint\n",
    "from torchsummary import summary\n",
    "from wholeslidedata.annotation import utils as annotation_utils\n",
    "from label_utils import to_dysplastic_vs_non_dysplastic\n",
    "from train_unet import load_config\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import yaml\n",
    "import wandb\n",
    "import os\n",
    "from distutils.dir_util import copy_tree\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10125c17-e713-4a41-8249-ca1cfc29e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some colors\n",
    "colors_1 = [\"white\", \"green\", \"orange\", \"red\", 'yellow', 'yellow', 'purple', 'pink', 'grey', \"blue\"]\n",
    "colors_2 = [\"white\", \"green\", \"red\", \"yellow\", 'brown', 'yellow', 'purple', 'pink', 'grey', 'green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c4709-aee5-4060-a1be-32c81236b246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img, cropx, cropy):\n",
    "    _, x, y, _ = img.shape\n",
    "    startx = x // 2 - (cropx // 2)\n",
    "    starty = y // 2 - (cropy // 2)\n",
    "    return img[:, starty:starty + cropy, startx:startx + cropx, :]\n",
    "\n",
    "def plot_center_batch(x, y, y_hat, patches=4):   \n",
    "    \n",
    "    # how many patches to plot\n",
    "    patches = len(y_hat) if patches > len(y_hat) else patches\n",
    "    \n",
    "    # get the prediction\n",
    "    y_hat = torch.argmax(y_hat, dim=1).cpu().detach().numpy()\n",
    "    \n",
    "    # center crop the image\n",
    "    _, h, w = y_hat.shape\n",
    "    x = crop_center(x, h, w)\n",
    "    \n",
    "    print(\"Ground truth\")\n",
    "    fig, axes = init_plot(1, patches, size=(30, 10))\n",
    "    plot_batch(axes, 0, x[:patches], y[:patches], alpha=0.3, colors=colors_2)\n",
    "    plt.show()\n",
    "\n",
    "    # pad and show prediction\n",
    "    print(\"Prediction\")\n",
    "    fig, axes = init_plot(1, patches, size=(30, 10))\n",
    "    plot_batch(axes, 0, x[:patches], y_hat[:patches], alpha=0.3, colors=colors_2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6c998-fd8c-47fd-9890-6f9d69d1ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config path\n",
    "base_dir = '/home/mbotros/code/barrett_gland_grading/'\n",
    "experiments_dir = '/home/mbotros/experiments/barrett_gland_grading'\n",
    "user_config = os.path.join(base_dir, 'configs/unet_training_config.yml')\n",
    "train_config = load_config(user_config)\n",
    "run_name = 'test_bolero'\n",
    "\n",
    "# make experiment dir & copy source files (config and training script)\n",
    "exp_dir = os.path.join(experiments_dir, run_name)\n",
    "print('Experiment stored at: {}'.format(exp_dir))\n",
    "copy_tree(os.path.join(base_dir, 'configs'), os.path.join(exp_dir, 'src', 'configs'))\n",
    "copy_tree(os.path.join(base_dir, 'nn_archs'), os.path.join(exp_dir, 'src', 'nn_archs'))\n",
    "shutil.copy2(os.path.join(base_dir, 'train_unet.py'), os.path.join(exp_dir, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f4988-800f-45da-b4ac-d1704f28dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets print some configs\n",
    "with open(user_config, 'r') as yamlfile:\n",
    "    data = yaml.load(yamlfile, Loader=yaml.FullLoader)\n",
    "    \n",
    "for k, v in data['wholeslidedata']['default'].items():\n",
    "    print('{}: {}'.format(k, v))\n",
    "\n",
    "# create train and validation generators\n",
    "training_batch_generator = create_batch_iterator(user_config=user_config,\n",
    "                                                 mode='training',\n",
    "                                                 cpus=train_config['cpus'])\n",
    "\n",
    "validation_batch_generator = create_batch_iterator(mode='validation',\n",
    "                                                   user_config=user_config,\n",
    "                                                   cpus=train_config['cpus'])\n",
    "\n",
    "print('\\nTraining dataset ')\n",
    "print_dataset_statistics(training_batch_generator.dataset)\n",
    "print('\\nValidation dataset ')\n",
    "print_dataset_statistics(validation_batch_generator.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6175a1e-33be-4e1a-9bdb-8a51171206ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally defined UNet (with valid convolutions)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(n_channels=train_config['n_channels'], n_classes=train_config['n_classes'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e6f95d-4dc0-45d0-bb2f-36e8cfc2328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_config['learning_rate'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# log with weights and biases\n",
    "# os.environ[\"WANDB_API_KEY\"] = '272782fa3a98a5f215cc2e580ebb4628245ea8e8'\n",
    "# wandb.init(project=\"Barrett's Gland Grading\", dir=exp_dir)\n",
    "# wandb.run.name = run_name\n",
    "\n",
    "min_val = float('inf')\n",
    "\n",
    "for n in range(train_config['epochs']):\n",
    "\n",
    "    train_metrics = {}\n",
    "    validation_metrics = {}\n",
    "\n",
    "    for idx in tqdm(range(train_config['train_batches']), desc='Epoch {}'.format(n + 1)):\n",
    "        x, y, info = next(training_batch_generator)\n",
    "\n",
    "        # dysplastic vs non-dysplastic\n",
    "        y = to_dysplastic_vs_non_dysplastic(y)\n",
    "        \n",
    "       # store one example as numpy\n",
    "        example_train_batch_x = x\n",
    "        example_train_batch_y = y\n",
    "\n",
    "        # transform x and y\n",
    "        x = torch.tensor(x.astype('float32'))\n",
    "        x = torch.transpose(x, 1, 3).to(device)\n",
    "        y = torch.tensor(y.astype('int64')).to(device)\n",
    "\n",
    "        # forward and update\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model.forward(x)\n",
    "        example_train_batch_y_hat = y_hat\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # compute and store metrics\n",
    "        y = y.cpu().detach().numpy().flatten()\n",
    "        y_hat = torch.argmax(y_hat, dim=1).cpu().detach().numpy().flatten()\n",
    "        train_metrics[idx] = {'loss': loss.item(),\n",
    "                              'dice per class': f1_score(y, y_hat, average=None, labels=[0, 1, 2]),\n",
    "                              'dice weighted': f1_score(y, y_hat, average='weighted')}\n",
    "\n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "        for idx in tqdm(range(train_config['val_batches']), desc='Validating'):\n",
    "            x, y, info = next(validation_batch_generator)\n",
    "            \n",
    "            # dysplastic vs non-dysplastic\n",
    "            y = to_dysplastic_vs_non_dysplastic(y)\n",
    "            \n",
    "            # store one example as numpy\n",
    "            example_val_batch_x = x\n",
    "            example_val_batch_y = y\n",
    "\n",
    "            # transform x and y\n",
    "            x = torch.tensor(x.astype('float32'))\n",
    "            x = torch.transpose(x, 1, 3).to(device)\n",
    "            y = torch.tensor(y.astype('int64')).to(device)\n",
    "\n",
    "            # forward and validate\n",
    "            y_hat = model.forward(x)\n",
    "            example_val_batch_y_hat = y_hat\n",
    "            loss = criterion(y_hat, y)\n",
    "\n",
    "            # compute dice\n",
    "            y = y.cpu().detach().numpy().flatten()\n",
    "            y_hat = torch.argmax(y_hat, dim=1).cpu().detach().numpy().flatten()\n",
    "            validation_metrics[idx] = {'loss': loss.item(),\n",
    "                                       'dice per class': f1_score(y, y_hat, average=None, labels=[0, 1, 2]),\n",
    "                                       'dice weighted': f1_score(y, y_hat, average='weighted')}\n",
    "\n",
    "    # compute and print metrics\n",
    "    training_means = mean_metrics(train_metrics)\n",
    "    validation_means = mean_metrics(validation_metrics)\n",
    "    print(\"Train loss: {:.3f}, val loss: {:.3f}\".format(training_means['loss'], validation_means['loss']))\n",
    "    print(\"Train dice: {}, val dice: {}\".format(np.round(training_means['dice per class'], decimals=2),\n",
    "                                                np.round(validation_means['dice per class'], decimals=2)))\n",
    "    # plot predictions\n",
    "    print('Training examples: ')\n",
    "    plot_center_batch(example_train_batch_x, example_train_batch_y, example_train_batch_y_hat)\n",
    "    print('Validation examples: ')\n",
    "    plot_center_batch(example_val_batch_x, example_val_batch_y, example_val_batch_y_hat)\n",
    "    \n",
    "    # wandb.log({'epoch': n + 1,\n",
    "    #            'train loss': training_means['loss'], 'train dice': training_means['dice weighted'],\n",
    "    #            'val loss': validation_means['loss'], 'val dice': validation_means['dice weighted']})\n",
    "\n",
    "    # save best model\n",
    "    if validation_means['loss'] < min_val:\n",
    "        torch.save(model.state_dict(),\n",
    "                   os.path.join(exp_dir, 'model_epoch_{}_loss_{:.3f}.pt').format(n, validation_means['loss']))\n",
    "        min_val = validation_means['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a15eb-0290-4266-818c-389eb5601234",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}