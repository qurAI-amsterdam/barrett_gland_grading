{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595e01c-a819-45f5-91e2-424d2b6d937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import sys\n",
    "import yaml\n",
    "from wholeslidedata.iterators import create_batch_iterator\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from matplotlib import patches\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import print_dataset_statistics, plot_pred_batch, load_config, plot_batch\n",
    "from train_segmentation import load_segmentation_model\n",
    "from preprocessing import tissue_mask_batch, get_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ab678-e482-4bc5-ab83-d77eb87fda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_segmentation_model(exp_dir, model_path):\n",
    "    \"\"\" Loads the trained model.\n",
    "\n",
    "    Args:\n",
    "        exp_dir: directory that hold all the information from an experiments (src, checkpoints)\n",
    "\n",
    "    \"\"\"\n",
    "    user_config = os.path.join(exp_dir, 'src/configs/base_config.yml')\n",
    "    _, train_config = load_config(user_config)\n",
    "\n",
    "    # LOAD MODEL\n",
    "    model = load_segmentation_model(train_config, activation=None)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    print('Loaded model from {}'.format(model_path))\n",
    "    \n",
    "    # LOAD PREPROCESSING\n",
    "    if train_config['encoder_weights']:\n",
    "        preprocessing = get_preprocessing(smp.encoders.get_preprocessing_fn(\n",
    "            train_config['encoder_name'], train_config['encoder_weights']))\n",
    "    else:\n",
    "        preprocessing = get_preprocessing()\n",
    "    print('During training we used {} as encoder with weights from {}.'.format(train_config['encoder_name'], train_config['encoder_weights']))   \n",
    "    \n",
    "    return model, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068f688-abd3-4997-ad52-17c8ea770c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dys_score_batch(x, y, y_hat):\n",
    "    \"\"\" simple dysplasia probability score computed as #NDBE voxels / #DYS voxels\n",
    "    \n",
    "    Args:\n",
    "        x: [B, H, W, CHANNELS]\n",
    "            (np.array)\n",
    "        y: [B, H, W]\n",
    "            (np.array)\n",
    "        y_hat: [B, CLASSES, H, W]\n",
    "            (torch.Tensor)\n",
    "            \n",
    "    Returns\n",
    "        dys_score: [B, 1]\n",
    "            (np.array)\n",
    "    \"\"\"\n",
    "    y_hat_soft = torch.nn.functional.softmax(y_hat, dim=1)\n",
    "    y_hat_p_ndbe = y_hat_soft[:, 1, :, :].cpu().detach().numpy()\n",
    "    y_hat_p_dys = y_hat_soft[:, 2, :, :].cpu().detach().numpy()\n",
    "    dys_score = np.sum(y_hat_p_ndbe, axis=(1, 2)) / np.sum(y_hat_p_dys, axis=(1, 2))\n",
    "    \n",
    "    return dys_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84db900-94b6-4d3b-9c7b-0a1089c90965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config path\n",
    "base_dir = '/home/mbotros/code/barrett_gland_grading/'\n",
    "classification_config = os.path.join(base_dir, 'configs/classification_config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80420674-4d56-471b-8ad1-5eb60b23b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "print('Loaded config: {}'.format(classification_config))\n",
    "\n",
    "with open(classification_config, 'r') as yamlfile:\n",
    "    data = yaml.load(yamlfile, Loader=yaml.FullLoader)\n",
    "\n",
    "wholeslide_config = data['wholeslidedata']\n",
    "\n",
    "# create train and validation generators (no reset)\n",
    "# training_batch_generator = create_batch_iterator(user_config=classification_config,\n",
    "#                                                  mode='training',\n",
    "#                                                  cpus=1)\n",
    "\n",
    "validation_batch_generator = create_batch_iterator(mode='validation',\n",
    "                                                   user_config=classification_config,\n",
    "                                                   presets=('slidingwindow',),\n",
    "                                                   cpus=1,\n",
    "                                                   number_of_batches=-1,\n",
    "                                                   return_info=True)\n",
    "                                                   \n",
    "    \n",
    "print('\\nTraining dataset ')\n",
    "train_data_dict = print_dataset_statistics(training_batch_generator.dataset)\n",
    "print('\\nValidation dataset ')\n",
    "val_data_dict = print_dataset_statistics(validation_batch_generator.dataset)\n",
    "\n",
    "print('number of annotations', len(validation_batch_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4efe77-9ac4-49e2-bbbd-6ee0be49e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = '/data/archief/AMC-data/Barrett/experiments/barrett_gland_grading/NDvsD/UNet++_EfficientNet-b4_sp=1_Dice/'\n",
    "model_path = os.path.join(exp_dir, 'checkpoints/model_epoch_142_loss_0.129_dice_0.822.pt')\n",
    "model, preprocessing = load_trained_segmentation_model(exp_dir, model_path)\n",
    "\n",
    "# declare device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd19fd9-ec2e-41ad-ba58-12baf941e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, generator, preprocessing):\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for x_batch, y_batch, info in tqdm(generator):\n",
    "            for idx, (x_np, y_np) in enumerate(zip(x_batch, y_batch)):\n",
    "                \n",
    "                # keep track of where samples are coming from\n",
    "                point = info['sample_references'][idx]['point']\n",
    "                wsi = info['sample_references'][idx]['reference'].file_key\n",
    "                \n",
    "                # preprocess patches\n",
    "                sample = preprocessing(image=np.expand_dims(x_np, axis=0), mask=np.expand_dims(y_np, axis=0))\n",
    "                x, y = sample['image'].to(device), sample['mask'].to(device)\n",
    "\n",
    "                # forward\n",
    "                y_hat = model(x)\n",
    "                y_hat_np = y_hat.cpu().detach().numpy()\n",
    "            \n",
    "                # compute dysplasia scores for batch\n",
    "                score = dys_score_batch(x_np, y_np, y_hat)\n",
    "                print('idx', idx, 'x_shape', x_np.shape, 'wsi', wsi,  point, 'score', score)\n",
    "\n",
    "                if wsi in results:\n",
    "                    results[wsi].append(score)   \n",
    "                else: \n",
    "                    results[wsi] = [score]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4036857-39f3-4d96-aac9-2a8fa4355682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dysplasia probablities\n",
    "results = infer(model, validation_batch_generator, preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac8700-ce44-4ec7-b118-4c38f19e7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rbe case level diagnosis\n",
    "rbe_case_df = pd.read_csv('/data/archief/AMC-data/Barrett/labels/rbe_case_level.csv')\n",
    "display(rbe_case_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}