{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a068a6-0e30-41ef-b69c-8c1c0d4c7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib import patches\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from wholeslidedata.annotation.parser import MaskAnnotationParser\n",
    "from wholeslidedata.image.wholeslideimage import WholeSlideImage\n",
    "from wholeslidedata.iterators import create_batch_iterator\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90533d0-6412-4d34-9672-190af352725a",
   "metadata": {},
   "source": [
    "### In this notebook we evaluate trained models on slide level.\n",
    " 1. Load the configuration and the trained model from the corresponding experiment folder. \n",
    " 2. Extract patches sliding windows fashion from the WSI.\n",
    "     * Use tissue mask to only extract patches from interesting regions.\n",
    " 3. Inferences on patches and stitch results back together.\n",
    " 4. Compute Dice score and confusion matrix on pixel level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea764e-507f-4688-8e29-7e3d0dd6833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_wsi = 'C:/Users/mbotros/PhD/data/ASL/ASL01_3_HE.tiff'\n",
    "\n",
    "# open with asap backend\n",
    "with WholeSlideImage(path_to_wsi, backend='asap') as wsi:\n",
    "    print(f'Backend used: {wsi.__class__}\\n')\n",
    "\n",
    "# open with openslide backend\n",
    "with WholeSlideImage(path_to_wsi, backend='openslide') as wsi:\n",
    "    print(f'Backend used: {wsi.__class__}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031680b-b545-4b46-b900-4d97a9efb1b4",
   "metadata": {},
   "source": [
    "#### Load config and trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f3e7ac-946d-4305-a6e0-222471b5b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "exp_dir = '/data/archief/AMC-data/Barrett/experiments/barrett_gland_grading/NDvsD_DeepLab_Res34_sp1_ps_1024_aug_scheduler/'\n",
    "model_path = os.path.join(exp_dir, 'checkpoints/model_epoch_54_loss_0.147_dice_0.946.pt')\n",
    "\n",
    "user_config = '/home/mbotros/code/barrett_gland_grading/configs/slidingwindowconfig.yml'\n",
    "\n",
    "print('Loading config: {}'.format(user_config))\n",
    "print('Loading model from {}'.format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5f0f5-a34a-4568-8be4-3fbdd1dc07d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sliding window test iterator\n",
    "\n",
    "mode='test'\n",
    "with create_batch_iterator(mode=mode,\n",
    "                           user_config=user_config,\n",
    "                           presets=('folders',),\n",
    "                           cpus=1, \n",
    "                           number_of_batches=-1, \n",
    "                           return_info=True) as test_iterator:\n",
    "\n",
    "    print('number of annotations', len(test_iterator))\n",
    "\n",
    "    for x_batch, y_batch, info in tqdm(test_iterator):\n",
    "        for idx, (x_sample, y_sample) in enumerate(zip(x_batch, y_batch)):\n",
    "            point = info['sample_references'][idx]['point']\n",
    "            print('idx', idx, 'x_shape', x_sample.shape, 'mask_shape', y_sample.shape,  point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9944a-7e88-456a-b9e7-1f1235d854a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_generator.dataset.annotations_per_label_per_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eaf3df-0120-40f5-89bf-5c8650215579",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "for i, (x, y, info) in tqdm(enumerate(batch_generator)):\n",
    "\n",
    "    # INPUT\n",
    "    # x: [B, H, W, C]\n",
    "    # y: [B, H, W]\n",
    "\n",
    "    # dysplastic vs non-dysplastic\n",
    "    y = to_dysplastic_vs_non_dysplastic(y)\n",
    "\n",
    "    # TENSOR\n",
    "    # x: [B, C, H, W]\n",
    "    # y: [B, H, W]\n",
    "    x = torch.tensor(x.astype('float32'))\n",
    "    x = x.transpose(1, 3).transpose(2, 3).to(device)\n",
    "    y = torch.tensor(y.astype('int64')).to(device)\n",
    "\n",
    "    # forward\n",
    "    y_hat = model.forward(x)\n",
    "    \n",
    "    # compute and store metrics\n",
    "    y = y.cpu().detach().numpy().flatten()\n",
    "    y_hat = torch.argmax(y_hat, dim=1).cpu().detach().numpy().flatten()\n",
    "    metrics[i] = {'dice per class': f1_score(y, y_hat, average=None, labels=[0, 1, 2]),\n",
    "                  'dice weighted': f1_score(y, y_hat, average='weighted')}\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad6b1fc-8fcf-4ffc-af89-36ed8dd67568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
