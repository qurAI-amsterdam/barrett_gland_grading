{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d4c389-b34b-4ab0-ab64-96ae4e9fd07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "from wholeslidedata.image.wholeslideimage import WholeSlideImage\n",
    "from wholeslidedata.annotation.wholeslideannotation import WholeSlideAnnotation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from wholeslidedata.iterators import create_batch_iterator\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../..'))\n",
    "from utils import plot_batch, colors_1\n",
    "import segmentation_models_pytorch as smp\n",
    "import argparse\n",
    "from train_ensemble import Ensemble\n",
    "from confidence_calibration import avg_entropy_sk_per_patch\n",
    "from preprocessing import tissue_mask_batch, get_preprocessing\n",
    "from train_segmentation import load_trained_segmentation_model\n",
    "from train_ensemble import load_model, Ensemble, SingleModel\n",
    "from confidence_calibration import avg_entropy_sk, plot_class_probabilities_sample, plot_pred_sample, ece, brier_score, avg_entropy_sk_per_patch\n",
    "\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "from matplotlib.offsetbox import (TextArea, DrawingArea, OffsetImage, AnnotationBbox)\n",
    "\n",
    "from nn_archs.set_transformer import SetTransformer\n",
    "from train_slide_classification import SlideGradeModel\n",
    "from metrics_lib import _validate_probabilities\n",
    "from skimage.filters import gaussian\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from utils import plot_confusion_matrix, plot_roc_curves\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57ecd4c-83b1-49e4-a835-0365a4d555a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_slide(y_pred, epsilon=1e-5):\n",
    "    \"\"\" Computes the entropy per class vs the rest\n",
    "\n",
    "    Args:\n",
    "        y_pred: (C, )\n",
    "        epsilon: small number for computation\n",
    "\n",
    "    Returns:\n",
    "        avg_entropy_sk: (C, )\n",
    "    \"\"\"\n",
    "    # validate probabilities\n",
    "    _validate_probabilities(y_pred)\n",
    "\n",
    "    num_classes = y_pred.shape[0]\n",
    "    avg_entropy = np.zeros(num_classes)\n",
    "    max_entropy = np.log(2) * num_classes\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        \n",
    "        p_c = y_pred[c]\n",
    "        avg_entropy[c] = -np.sum(p_c * np.log(p_c + epsilon) + (1 - p_c) * np.log(1 - p_c + epsilon))\n",
    "\n",
    "    return avg_entropy / max_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378423f9-0d88-480c-94f5-0b8ba1ecb4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_pixel(y_pred, epsilon=1e-5):\n",
    "    \"\"\" Computes the average of pixel-wise entropy values for\n",
    "\n",
    "    Args:\n",
    "        y_pred: (N, C)\n",
    "        epsilon: small number for computation\n",
    "\n",
    "    Returns:\n",
    "        avg_entropy_sk: (C, )\n",
    "    \"\"\"\n",
    "    # validate probabilities\n",
    "    _validate_probabilities(y_pred)\n",
    "    num_classes = y_pred.shape[1]\n",
    "    avg_entropy = np.zeros(num_classes)\n",
    "\n",
    "    for c in range(num_classes):\n",
    "\n",
    "        # for every pixel the prob of c\n",
    "        p_c = y_pred[:, c]\n",
    "        avg_entropy[c] = -(1 / len(p_c)) * np.sum(p_c * np.log(p_c + epsilon) + (1 - p_c) * np.log(1 - p_c + epsilon))\n",
    "\n",
    "    return avg_entropy\n",
    "\n",
    "def entropy_pixel_per_patch(y_pred):\n",
    "    \"\"\" Compute the average entropy per patch in a batch\n",
    "\n",
    "    Args:\n",
    "        y_pred: (B, C, H, W)\n",
    "\n",
    "    Returns:\n",
    "        h: (B, C)\n",
    "    \"\"\"\n",
    "    h = np.zeros((y_pred.shape[0], y_pred.shape[1]))\n",
    "\n",
    "    for i, y_pred_patch in enumerate(y_pred):\n",
    "        y_pred_patch = np.transpose(y_pred_patch, (1, 2, 0)).reshape(-1, y_pred.shape[1])\n",
    "        h[i] = entropy_pixel(y_pred_patch)\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f09ef7e-06d7-4302-8dc6-230ce08a7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileGenerator:\n",
    "    '''Generates tiles for Numpy images\n",
    "    '''\n",
    "    def __init__(self, image, step_size, tile_size):\n",
    "        \n",
    "        self.image = image\n",
    "        self.tile_size = tile_size\n",
    "        self.step_size = step_size\n",
    "    \n",
    "    def get_generator(self):\n",
    "        img = self.image\n",
    "        width, height = img.shape[0], img.shape[1]\n",
    "        x_tiles = int(np.floor(width/self.step_size))\n",
    "        y_tiles = int(np.floor(height/self.step_size))\n",
    "\n",
    "        for y in range(y_tiles):\n",
    "            for x in range(x_tiles):\n",
    "                x_coord = int(np.round(x*self.step_size))\n",
    "                y_coord = int(np.round(y*self.step_size))\n",
    "                tile = img[x_coord: x_coord + self.tile_size, y_coord: y_coord + self.tile_size]\n",
    "                centre_coord = (x_coord, y_coord)\n",
    "\n",
    "                # remove when doesnt fit\n",
    "                if tile.shape == (self.tile_size, self.tile_size, 3):\n",
    "                    yield tile, centre_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf33dc4d-55f2-4e9f-8a72-4ce7d9b9124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) get tiles with overlap\n",
    "tile_size = 512\n",
    "step_size = 256\n",
    "spacing = 1\n",
    "\n",
    "def tile_generator(imgs, step_size, tile_size):\n",
    "    '''Generates tiles for Numpy images\n",
    "    '''\n",
    "    for img in imgs:\n",
    "        width, height = img.shape[0], img.shape[1]\n",
    "        x_tiles = int(np.floor(width/step_size))\n",
    "        y_tiles = int(np.floor(height/step_size))\n",
    "\n",
    "        for y in range(y_tiles):\n",
    "            for x in range(x_tiles):\n",
    "                x_coord = int(np.round(x*step_size))\n",
    "                y_coord = int(np.round(y*step_size))\n",
    "                tile = img[x_coord: x_coord + tile_size, y_coord: y_coord + tile_size]\n",
    "                centre_coord = (x_coord, y_coord)\n",
    "\n",
    "                # remove when doesnt fit\n",
    "                if tile.shape == (tile_size, tile_size, 3):\n",
    "                    yield tile, centre_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27578257-f74d-45b2-a481-4c99691779c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: unet++, weights: imagenet\n",
      "Loaded model from: /data/archief/AMC-data/Barrett/experiments/barrett_gland_grading/3_classes/Ensemble_m5_UNet++_CE_IN/net_0/checkpoints/best_model.pt\n",
      "\n",
      "Loading model: unet++, weights: imagenet\n",
      "Loaded model from: /data/archief/AMC-data/Barrett/experiments/barrett_gland_grading/3_classes/Ensemble_m5_UNet++_CE_IN/net_1/checkpoints/best_model.pt\n",
      "\n",
      "Loading model: unet++, weights: imagenet\n",
      "Loaded model from: /data/archief/AMC-data/Barrett/experiments/barrett_gland_grading/3_classes/Ensemble_m5_UNet++_CE_IN/net_2/checkpoints/best_model.pt\n",
      "\n",
      "Loading model: unet++, weights: imagenet\n",
      "Loaded model from: /data/archief/AMC-data/Barrett/experiments/barrett_gland_grading/3_classes/Ensemble_m5_UNet++_CE_IN/net_3/checkpoints/best_model.pt\n",
      "\n",
      "Loading model: unet++, weights: imagenet\n",
      "Loaded model from: /data/archief/AMC-data/Barrett/experiments/barrett_gland_grading/3_classes/Ensemble_m5_UNet++_CE_IN/net_4/checkpoints/best_model.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load ensemble of segmentation models\n",
    "exp_dir = '/data/archief/AMC-data/Barrett/experiments/barrett_gland_grading/3_classes/Ensemble_m5_UNet++_CE_IN/'\n",
    "preprocessing = get_preprocessing(smp.encoders.get_preprocessing_fn('efficientnet-b4', 'imagenet'))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "ensemble_m5_CE_IN = Ensemble(exp_dir, device=device, m=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023175e8-2e43-4da9-916b-935dfb835d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tiles_2(model, generator, preprocessing, device):\n",
    "    \"\"\" Extracts tiles.\n",
    "\n",
    "    Args:\n",
    "            model:\n",
    "            batch_iterator:\n",
    "            preprocessing:\n",
    "            device:\n",
    "\n",
    "    Returns:\n",
    "            info_tiles:\n",
    "    \"\"\"\n",
    "    info_tiles = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (x_np, loc) in enumerate(tqdm(generator)):\n",
    "            \n",
    "            # pre process and put on device\n",
    "            x = preprocessing(image=np.expand_dims(x_np, axis=0))['image'].to(device)\n",
    "            y = torch.zeros_like(x)\n",
    "  \n",
    "            # forward\n",
    "            y_hat = model.forward(x, y)\n",
    "\n",
    "            # naive max grade prediction \n",
    "            y_pred_max_grade = np.max(np.argmax(y_hat, axis=1), axis=(1, 2))       # (B, 1)\n",
    "            avg_msp = np.mean(y_hat, axis=(2, 3))                                  # (B, C)\n",
    "            \n",
    "            # entropy (uncertainty score)\n",
    "            avg_entropy = avg_entropy_sk_per_patch(y_hat)\n",
    "            avg_entropy_pixel = entropy_pixel_per_patch(y_hat)\n",
    "            y_hat_nd_vs_d = np.add.reduceat(y_hat, indices=[0, 1, 2], axis=1)\n",
    "            avg_msp_nd_vs_d = np.mean(y_hat_nd_vs_d, axis=(2, 3))  \n",
    "            avg_entropy_nd_vs_d = avg_entropy_sk_per_patch(y_hat_nd_vs_d)\n",
    "                       \n",
    "            for i in range(len(y_hat)):\n",
    "                \n",
    "                # print('Idx: {}, point:  {}, shape: {}: '.format(idx, point, x_np[i].shape))\n",
    "                info_tiles.append({'loc': loc, \n",
    "                                   'naive_pred': y_pred_max_grade[i], \n",
    "                                   'avg_msp': avg_msp[i],\n",
    "                                   'avg_msp_nd_vs_d': avg_msp_nd_vs_d[i],\n",
    "                                   'avg_msp_pred': avg_msp[i][y_pred_max_grade[i]],\n",
    "                                   'entropy_pred': avg_entropy[i][y_pred_max_grade[i]], \n",
    "                                   'entropy_sk': avg_entropy[i],\n",
    "                                   'entropy_pixel': avg_entropy_pixel[i],\n",
    "                                   'entropy_nd_vs_d': avg_entropy_nd_vs_d[i],\n",
    "                                   'avg_msp_dys': avg_msp_nd_vs_d[i][2],\n",
    "                                   'entropy_dys': avg_entropy_nd_vs_d[i][2]}) \n",
    "                \n",
    "    return pd.DataFrame(info_tiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c95c5-b75f-4b08-badb-7e82bd6ab09b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a65c4dba-0b4f-48b6-98e5-17e4885bd6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide</th>\n",
       "      <th>grade_num</th>\n",
       "      <th>grade</th>\n",
       "      <th>grade normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASL01_3_HE</td>\n",
       "      <td>3</td>\n",
       "      <td>LGD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASL02_1_HE</td>\n",
       "      <td>1</td>\n",
       "      <td>NDBE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASL03_1_HE</td>\n",
       "      <td>3</td>\n",
       "      <td>LGD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASL04_1_HE</td>\n",
       "      <td>1</td>\n",
       "      <td>NDBE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASL05_1_HE</td>\n",
       "      <td>1</td>\n",
       "      <td>NDBE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>ROCT38_XI-HE1</td>\n",
       "      <td>4</td>\n",
       "      <td>HGD</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>ROCT38_XII-HE1</td>\n",
       "      <td>1</td>\n",
       "      <td>NDBE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>ROCT39_V-HE1</td>\n",
       "      <td>4</td>\n",
       "      <td>HGD</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>ROCT39_VI-HE1</td>\n",
       "      <td>4</td>\n",
       "      <td>HGD</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>ROCT51_VI-HE1</td>\n",
       "      <td>4</td>\n",
       "      <td>HGD</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              slide  grade_num grade  grade normal\n",
       "0        ASL01_3_HE          3   LGD             2\n",
       "1        ASL02_1_HE          1  NDBE             1\n",
       "2        ASL03_1_HE          3   LGD             2\n",
       "3        ASL04_1_HE          1  NDBE             1\n",
       "4        ASL05_1_HE          1  NDBE             1\n",
       "..              ...        ...   ...           ...\n",
       "285   ROCT38_XI-HE1          4   HGD             3\n",
       "286  ROCT38_XII-HE1          1  NDBE             1\n",
       "287    ROCT39_V-HE1          4   HGD             3\n",
       "288   ROCT39_VI-HE1          4   HGD             3\n",
       "289   ROCT51_VI-HE1          4   HGD             3\n",
       "\n",
       "[290 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load rbe case level diagnosis\n",
    "rbe_slide_df = pd.read_csv('/data/archief/AMC-data/Barrett/labels/rbe_slide_level.csv')\n",
    "rbe_slide_df['grade normal'] = rbe_slide_df['grade'].map({'NDBE': 1, 'LGD': 2, 'HGD': 3})\n",
    "display(rbe_slide_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0b14510-e796-4da2-af83-3f04c2394d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "/data/archief/AMC-data/Barrett/ASL/ASL24_1_HE.tiff\n"
     ]
    }
   ],
   "source": [
    "# path to the datasets                      \n",
    "split_file = '/home/mbotros/code/barrett_gland_grading/configs/split.yml'\n",
    "dataset = 'validation'\n",
    "\n",
    "# open the file and load the file\n",
    "with open(split_file) as f:\n",
    "    data = yaml.load(f, Loader=SafeLoader)\n",
    "    wsi_path_list = [x['wsi']['path'] for x in data[dataset]]\n",
    "\n",
    "print(len(wsi_path_list))\n",
    "print(wsi_path_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b49c218b-9e68-45a5-9973-fc3639a3bba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# get the files that are in both (the GT and in the file list)\n",
    "groundtruth_cases = list(rbe_slide_df.slide)\n",
    "file_cases = [f.split('/')[-1][:-5] for f in wsi_path_list]\n",
    "cases = [slide for slide in file_cases if slide in groundtruth_cases]\n",
    "print(len(cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e0174-9f89-4638-becd-448b03b6787a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.zeros((len(cases), 250, 4))\n",
    "y = np.zeros((len(cases), 1))\n",
    "n = []\n",
    "\n",
    "for idx, case in enumerate(tqdm(cases)):\n",
    "    \n",
    "    # look up the label of this case\n",
    "    n.append(case)\n",
    "    wsi_path = [s for s in wsi_path_list if case in s][0]\n",
    "    grade = int(rbe_slide_df[rbe_slide_df['slide'] == case]['grade normal']) - 1\n",
    "    y[idx] = grade\n",
    "    print('Processing case: {}\\nPath: {}\\nLabel: {}\\n'.format(case, wsi_path, grade))\n",
    "    \n",
    "    # open the image with spacing 1\n",
    "    with WholeSlideImage(wsi_path, backend='openslide') as wsi:\n",
    "        slide = wsi.get_slide(spacing=1)\n",
    "\n",
    "    # tile gen WSI level: overlapping sliding window\n",
    "    tile_gn = tile_generator(imgs=[slide], step_size=step_size, tile_size=tile_size)\n",
    "    \n",
    "    # apply ensemble over the tiles\n",
    "    info_tiles = extract_tiles_2(model=ensemble_m5_CE_IN, generator=tile_gn, preprocessing=preprocessing, device=device)\n",
    "    \n",
    "    # rank on entropy\n",
    "    sus_tiles =  info_tiles[info_tiles['naive_pred'] > 1].sort_values(by=['entropy_dys'])[:250]\n",
    "\n",
    "    if len(sus_tiles) == 0:\n",
    "        print('Did not find any evidence of dysplasia.')\n",
    "        sus_tiles = info_tiles[info_tiles['naive_pred'] > 0].sort_values(by=['entropy_dys'])[:250]\n",
    "\n",
    "    for tile_idx, tile in sus_tiles.reset_index().iterrows():      \n",
    "        x[idx, tile_idx, 0:4] = tile['entropy_sk']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccd17757-5310-4979-bbc2-10485a70fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store features\n",
    "classification_exp_dir = '/data/archief/AMC-data/Barrett/experiments/barrett_slide_classification/entropy_features_wsi/'\n",
    "x_save_path = os.path.join(classification_exp_dir, 'x_test_overlap')\n",
    "y_save_path = os.path.join(classification_exp_dir, 'y_test_overlap')\n",
    "\n",
    "# np.save(file=x_save_path, arr=x)\n",
    "# np.save(file=y_save_path, arr=y)\n",
    "# y_names_save_path = os.path.join(classification_exp_dir, 'y_test_names')\n",
    "# np.save(file=y_names_save_path, arr=n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
